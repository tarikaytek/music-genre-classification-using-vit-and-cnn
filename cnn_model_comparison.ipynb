{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, image_size, batch_size=64, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Loads images with some preprocessing into train and test data generators using tensorflow's ImageDataGenerator\n",
    "    :folder_path: folder location of the images\n",
    "    :image_size: wanted size after loading\n",
    "    :batch_size: how many images at once the data generator will generate\n",
    "    \"\"\"\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=test_size)\n",
    "    \n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        folder_path,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    validation_data_generator = datagen.flow_from_directory(\n",
    "        folder_path,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    return data_generator, validation_data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class implementation for CNN models. InÄ±tializes a model with given parameters with Tensorflow's Sequential\n",
    "class CNNClassifier:\n",
    "    def __init__(self, num_conv_layers=2, num_filters=32, kernel_size=(3, 3), input_shape=(128, 128, 3), num_classes=10):\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(self.num_filters, self.kernel_size, activation='relu', input_shape=self.input_shape))\n",
    "        model.add(layers.MaxPooling2D((2, 2))) \n",
    "        for _ in range(self.num_conv_layers - 1):   # Add wanted num_conv_layers - 1 layer after input layer\n",
    "            model.add(layers.Conv2D(self.num_filters, self.kernel_size, activation='relu'))\n",
    "            model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',   #sparse has chosen for this specific task\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, train_data, validation_data, epochs=10, batch_size=64):\n",
    "        self.history = self.model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, test_data, y_true):\n",
    "        y_pred = self.model.predict_classes(test_data)\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "        print(\"\\nAccuracy:\", accuracy_score(y_true, y_pred))\n",
    "        return y_pred\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        history = self.history\n",
    "\n",
    "        # Plot training and validation accuracy\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot training and validation loss\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model for each combination of hyperparameter search space, train, save the important result features, return a results dataframe \n",
    "def model_comparison(data_folder, img_size_list, num_filters_list, kernel_size_list, num_conv_layers_list):\n",
    "    results = []\n",
    "    \n",
    "    # Choosing each combination by for loops\n",
    "    for img_size in img_size_list:\n",
    "        train_data_generator, validation_data_generator = load_images(data_folder, img_size)    # Load the data only once as it has only one tuned hyperparameter\n",
    "        input_shape = img_size + (3,)\n",
    "        for num_filters in num_filters_list:\n",
    "            for kernel_size in kernel_size_list:\n",
    "                for num_conv_layers in num_conv_layers_list:\n",
    "                    print(f\"\\nTraining with the hyperparameters:\\nImage size: {img_size}    Number of convolution layers: {num_conv_layers}    Number of filters: {num_filters}   Kernel size: {kernel_size}\")\n",
    "                    \n",
    "                    model = CNNClassifier(num_conv_layers=num_conv_layers, num_filters=num_filters, kernel_size=kernel_size, input_shape=input_shape)\n",
    "                    \n",
    "                    # Calculate training time for comparison\n",
    "                    start_time = time.time()\n",
    "                    model.train(train_data_generator, validation_data_generator)\n",
    "                    end_time = time.time()\n",
    "                    training_time = round(end_time - start_time, 1)     # Rounds it to 1 digit sensitivity for readibility\n",
    "                    \n",
    "                    # Takes the last epoch's value and rounds it to 3 digit sensitivity for readibility\n",
    "                    train_acc = round(model.history.history['accuracy'][-1], 3)\n",
    "                    test_acc = round(model.history.history['val_accuracy'][-1], 3)\n",
    "                    train_loss = round(model.history.history['loss'][-1], 3)\n",
    "                    test_loss = round(model.history.history['val_loss'][-1], 3)\n",
    "\n",
    "                    # Saves result in a dictionary\n",
    "                    result = {\n",
    "                        'img_size': img_size,\n",
    "                        'num_conv_layers': num_conv_layers,\n",
    "                        'num_filters': num_filters,\n",
    "                        'kernel_size': kernel_size,\n",
    "                        'train accuracy': train_acc,\n",
    "                        'test accuracy': test_acc,\n",
    "                        'train loss': train_loss,\n",
    "                        'test_loss': test_loss,\n",
    "                        'training time': training_time\n",
    "                    }\n",
    "                    results.append(result)  # Merges all model's result\n",
    "                    del model   # Deletes the last model for less memory usage\n",
    "                    \n",
    "    return pd.DataFrame(results)    # Returns as dataframe for readibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of folder where the data is \n",
    "data_folder = \"C:\\\\20+\\\\bitirme\\\\spectrograms\\\\stft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search space, each of them must be a list of proper hyperparameters\n",
    "img_size_list = [(256, 128), (256, 256), (128, 128)]\n",
    "num_filters_list = [32, 64]\n",
    "kernel_size_list = [(3, 3), (5, 5)]\n",
    "num_conv_layers_list = [2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 10 classes.\n",
      "Found 199 images belonging to 10 classes.\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 2    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 10s 763ms/step - loss: 2.9467 - accuracy: 0.1737 - val_loss: 2.1445 - val_accuracy: 0.1307\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 9s 724ms/step - loss: 2.0253 - accuracy: 0.1975 - val_loss: 1.8986 - val_accuracy: 0.1608\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 10s 739ms/step - loss: 1.7562 - accuracy: 0.3638 - val_loss: 1.8190 - val_accuracy: 0.2613\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 9s 722ms/step - loss: 1.5081 - accuracy: 0.4837 - val_loss: 1.8634 - val_accuracy: 0.3819\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 9s 692ms/step - loss: 1.2282 - accuracy: 0.5962 - val_loss: 1.7776 - val_accuracy: 0.3317\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 9s 725ms/step - loss: 1.0489 - accuracy: 0.6525 - val_loss: 1.6383 - val_accuracy: 0.4271\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 9s 699ms/step - loss: 0.8348 - accuracy: 0.7362 - val_loss: 1.8358 - val_accuracy: 0.4221\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 9s 703ms/step - loss: 0.7328 - accuracy: 0.7812 - val_loss: 1.6300 - val_accuracy: 0.4070\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 9s 704ms/step - loss: 0.5773 - accuracy: 0.8250 - val_loss: 1.8393 - val_accuracy: 0.3920\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 9s 698ms/step - loss: 0.4928 - accuracy: 0.8438 - val_loss: 1.7151 - val_accuracy: 0.4221\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 3    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 10s 704ms/step - loss: 2.2457 - accuracy: 0.1600 - val_loss: 2.0223 - val_accuracy: 0.2060\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 9s 670ms/step - loss: 1.9215 - accuracy: 0.3025 - val_loss: 1.8055 - val_accuracy: 0.2814\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 9s 664ms/step - loss: 1.7037 - accuracy: 0.3750 - val_loss: 1.7974 - val_accuracy: 0.3065\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 1.5596 - accuracy: 0.4200 - val_loss: 1.7175 - val_accuracy: 0.3065\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 9s 679ms/step - loss: 1.4767 - accuracy: 0.4650 - val_loss: 1.8307 - val_accuracy: 0.2915\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 9s 692ms/step - loss: 1.4416 - accuracy: 0.4650 - val_loss: 1.8005 - val_accuracy: 0.3367\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 9s 663ms/step - loss: 1.3237 - accuracy: 0.5150 - val_loss: 1.7665 - val_accuracy: 0.3015\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 9s 661ms/step - loss: 1.2497 - accuracy: 0.5512 - val_loss: 1.7181 - val_accuracy: 0.3266\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 9s 663ms/step - loss: 1.0801 - accuracy: 0.6012 - val_loss: 1.9420 - val_accuracy: 0.3920\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 9s 668ms/step - loss: 0.9851 - accuracy: 0.6425 - val_loss: 1.5639 - val_accuracy: 0.4724\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 4    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 10s 691ms/step - loss: 2.2279 - accuracy: 0.2288 - val_loss: 1.9922 - val_accuracy: 0.3266\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 9s 689ms/step - loss: 1.8666 - accuracy: 0.3150 - val_loss: 1.8129 - val_accuracy: 0.3116\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 9s 671ms/step - loss: 1.7295 - accuracy: 0.3487 - val_loss: 1.7420 - val_accuracy: 0.3719\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 9s 671ms/step - loss: 1.6020 - accuracy: 0.4150 - val_loss: 1.7731 - val_accuracy: 0.3518\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 9s 666ms/step - loss: 1.5951 - accuracy: 0.4238 - val_loss: 1.7735 - val_accuracy: 0.3668\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 9s 669ms/step - loss: 1.5056 - accuracy: 0.4387 - val_loss: 1.7066 - val_accuracy: 0.3367\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 9s 665ms/step - loss: 1.4352 - accuracy: 0.4588 - val_loss: 1.7133 - val_accuracy: 0.3467\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 9s 666ms/step - loss: 1.3937 - accuracy: 0.4650 - val_loss: 1.7378 - val_accuracy: 0.3568\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 1.3147 - accuracy: 0.5125 - val_loss: 1.6626 - val_accuracy: 0.4221\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 9s 686ms/step - loss: 1.3102 - accuracy: 0.5188 - val_loss: 1.7265 - val_accuracy: 0.3819\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 2    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 11s 811ms/step - loss: 2.6338 - accuracy: 0.1437 - val_loss: 2.1610 - val_accuracy: 0.1709\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 10s 760ms/step - loss: 1.9843 - accuracy: 0.2475 - val_loss: 2.0102 - val_accuracy: 0.2864\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 10s 765ms/step - loss: 1.7777 - accuracy: 0.3775 - val_loss: 2.0105 - val_accuracy: 0.2060\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 10s 775ms/step - loss: 1.5437 - accuracy: 0.4762 - val_loss: 1.8740 - val_accuracy: 0.3618\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 10s 774ms/step - loss: 1.4988 - accuracy: 0.4812 - val_loss: 1.9103 - val_accuracy: 0.2462\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 10s 769ms/step - loss: 1.3468 - accuracy: 0.5412 - val_loss: 1.8345 - val_accuracy: 0.3367\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 10s 768ms/step - loss: 1.2327 - accuracy: 0.5725 - val_loss: 1.7262 - val_accuracy: 0.3819\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 10s 774ms/step - loss: 1.0111 - accuracy: 0.6413 - val_loss: 1.6401 - val_accuracy: 0.4523\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 10s 786ms/step - loss: 0.8712 - accuracy: 0.6963 - val_loss: 1.8772 - val_accuracy: 0.4271\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 11s 843ms/step - loss: 0.8037 - accuracy: 0.7337 - val_loss: 1.8118 - val_accuracy: 0.4472\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 3    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 11s 810ms/step - loss: 2.2124 - accuracy: 0.1663 - val_loss: 1.9934 - val_accuracy: 0.2111\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 10s 737ms/step - loss: 1.9064 - accuracy: 0.2725 - val_loss: 1.8902 - val_accuracy: 0.2965\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 9s 722ms/step - loss: 1.7017 - accuracy: 0.3875 - val_loss: 1.8924 - val_accuracy: 0.3166\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 10s 725ms/step - loss: 1.6302 - accuracy: 0.4087 - val_loss: 1.7885 - val_accuracy: 0.2965\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 9s 724ms/step - loss: 1.5542 - accuracy: 0.4375 - val_loss: 1.7817 - val_accuracy: 0.2965\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 10s 755ms/step - loss: 1.4348 - accuracy: 0.4600 - val_loss: 1.8009 - val_accuracy: 0.2965\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 10s 757ms/step - loss: 1.3147 - accuracy: 0.5400 - val_loss: 1.7006 - val_accuracy: 0.3970\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 10s 789ms/step - loss: 1.2596 - accuracy: 0.5625 - val_loss: 1.6052 - val_accuracy: 0.3769\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 10s 773ms/step - loss: 1.2160 - accuracy: 0.5850 - val_loss: 1.6442 - val_accuracy: 0.4322\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 10s 743ms/step - loss: 1.1458 - accuracy: 0.5850 - val_loss: 1.7846 - val_accuracy: 0.4070\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 4    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 11s 743ms/step - loss: 2.2433 - accuracy: 0.1513 - val_loss: 2.0597 - val_accuracy: 0.3367\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 10s 742ms/step - loss: 1.9798 - accuracy: 0.2625 - val_loss: 1.9280 - val_accuracy: 0.3719\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 10s 747ms/step - loss: 1.8135 - accuracy: 0.3475 - val_loss: 1.9904 - val_accuracy: 0.2513\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 10s 746ms/step - loss: 1.6778 - accuracy: 0.3725 - val_loss: 1.8794 - val_accuracy: 0.2362\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 10s 782ms/step - loss: 1.6421 - accuracy: 0.3887 - val_loss: 1.8222 - val_accuracy: 0.2613\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 12s 910ms/step - loss: 1.5318 - accuracy: 0.4387 - val_loss: 1.8879 - val_accuracy: 0.3166\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 10s 794ms/step - loss: 1.5885 - accuracy: 0.4375 - val_loss: 1.8899 - val_accuracy: 0.2312\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 10s 749ms/step - loss: 1.5593 - accuracy: 0.4450 - val_loss: 1.7927 - val_accuracy: 0.2663\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 10s 759ms/step - loss: 1.4537 - accuracy: 0.4700 - val_loss: 1.6762 - val_accuracy: 0.3568\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 10s 753ms/step - loss: 1.4210 - accuracy: 0.4938 - val_loss: 1.7420 - val_accuracy: 0.3216\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 2    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 16s 1s/step - loss: 2.5838 - accuracy: 0.1800 - val_loss: 2.1121 - val_accuracy: 0.2161\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.8884 - accuracy: 0.3137 - val_loss: 2.0842 - val_accuracy: 0.2864\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.6419 - accuracy: 0.4137 - val_loss: 1.9768 - val_accuracy: 0.2362\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.3903 - accuracy: 0.5075 - val_loss: 2.0202 - val_accuracy: 0.3015\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.1826 - accuracy: 0.5900 - val_loss: 1.7273 - val_accuracy: 0.3618\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.9617 - accuracy: 0.6875 - val_loss: 1.7773 - val_accuracy: 0.4121\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.7446 - accuracy: 0.7337 - val_loss: 1.7774 - val_accuracy: 0.4271\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.5368 - accuracy: 0.8250 - val_loss: 2.0502 - val_accuracy: 0.4573\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.4729 - accuracy: 0.8562 - val_loss: 2.2855 - val_accuracy: 0.4573\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.4221 - accuracy: 0.8675 - val_loss: 2.3562 - val_accuracy: 0.4070\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 3    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 2.2697 - accuracy: 0.1525 - val_loss: 1.9965 - val_accuracy: 0.2412\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 13s 994ms/step - loss: 1.9044 - accuracy: 0.3100 - val_loss: 1.9318 - val_accuracy: 0.2864\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 13s 976ms/step - loss: 1.7650 - accuracy: 0.3375 - val_loss: 1.7724 - val_accuracy: 0.3116\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 13s 1s/step - loss: 1.5602 - accuracy: 0.4338 - val_loss: 1.8090 - val_accuracy: 0.2814\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 13s 994ms/step - loss: 1.4891 - accuracy: 0.4625 - val_loss: 2.0280 - val_accuracy: 0.2814\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 13s 992ms/step - loss: 1.4400 - accuracy: 0.4563 - val_loss: 1.7817 - val_accuracy: 0.3116\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 13s 995ms/step - loss: 1.3065 - accuracy: 0.5213 - val_loss: 1.7276 - val_accuracy: 0.3970\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 13s 1000ms/step - loss: 1.2139 - accuracy: 0.5525 - val_loss: 1.5827 - val_accuracy: 0.4271\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 13s 981ms/step - loss: 1.1185 - accuracy: 0.5987 - val_loss: 1.6829 - val_accuracy: 0.4221\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 13s 1s/step - loss: 1.0734 - accuracy: 0.6112 - val_loss: 1.9971 - val_accuracy: 0.4322\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 4    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 2.2427 - accuracy: 0.1513 - val_loss: 1.9438 - val_accuracy: 0.3116\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 13s 1s/step - loss: 1.8899 - accuracy: 0.3137 - val_loss: 1.9398 - val_accuracy: 0.2663\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 13s 985ms/step - loss: 1.7409 - accuracy: 0.3663 - val_loss: 1.9188 - val_accuracy: 0.2111\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 13s 972ms/step - loss: 1.6480 - accuracy: 0.3887 - val_loss: 1.7718 - val_accuracy: 0.2663\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 13s 981ms/step - loss: 1.5489 - accuracy: 0.4363 - val_loss: 1.8911 - val_accuracy: 0.3166\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 13s 967ms/step - loss: 1.5190 - accuracy: 0.4363 - val_loss: 1.7279 - val_accuracy: 0.3266\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 13s 1s/step - loss: 1.4835 - accuracy: 0.4475 - val_loss: 1.6817 - val_accuracy: 0.4523\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 13s 973ms/step - loss: 1.3690 - accuracy: 0.5138 - val_loss: 1.7215 - val_accuracy: 0.3518\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 13s 978ms/step - loss: 1.3221 - accuracy: 0.5275 - val_loss: 1.9630 - val_accuracy: 0.3367\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 13s 968ms/step - loss: 1.3066 - accuracy: 0.5250 - val_loss: 1.6895 - val_accuracy: 0.4422\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 2    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 20s 1s/step - loss: 3.1393 - accuracy: 0.1375 - val_loss: 2.1362 - val_accuracy: 0.1960\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 2.0556 - accuracy: 0.2175 - val_loss: 2.0780 - val_accuracy: 0.2060\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.8863 - accuracy: 0.2962 - val_loss: 2.0091 - val_accuracy: 0.2161\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.7380 - accuracy: 0.3900 - val_loss: 1.8661 - val_accuracy: 0.2663\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.6140 - accuracy: 0.4112 - val_loss: 1.8977 - val_accuracy: 0.3266\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.6470 - accuracy: 0.4187 - val_loss: 1.9350 - val_accuracy: 0.2915\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.4944 - accuracy: 0.4663 - val_loss: 1.9459 - val_accuracy: 0.2613\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.4861 - accuracy: 0.4762 - val_loss: 1.9275 - val_accuracy: 0.3266\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.3708 - accuracy: 0.5387 - val_loss: 1.8417 - val_accuracy: 0.3467\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.2925 - accuracy: 0.5400 - val_loss: 1.9147 - val_accuracy: 0.3518\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 3    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 20s 2s/step - loss: 2.2297 - accuracy: 0.1863 - val_loss: 2.1453 - val_accuracy: 0.1809\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 19s 2s/step - loss: 1.9347 - accuracy: 0.3150 - val_loss: 2.0617 - val_accuracy: 0.2362\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.7579 - accuracy: 0.3500 - val_loss: 2.0135 - val_accuracy: 0.2764\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.7113 - accuracy: 0.3775 - val_loss: 1.8364 - val_accuracy: 0.3518\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.5828 - accuracy: 0.4200 - val_loss: 1.7938 - val_accuracy: 0.3668\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.4290 - accuracy: 0.4950 - val_loss: 1.8052 - val_accuracy: 0.3568\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.3415 - accuracy: 0.5000 - val_loss: 1.8266 - val_accuracy: 0.3819\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.2892 - accuracy: 0.5050 - val_loss: 1.6564 - val_accuracy: 0.4372\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.1825 - accuracy: 0.5788 - val_loss: 1.7310 - val_accuracy: 0.4171\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.0978 - accuracy: 0.6125 - val_loss: 1.9601 - val_accuracy: 0.4121\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 128)    Number of convolution layers: 4    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 20s 1s/step - loss: 2.2837 - accuracy: 0.1000 - val_loss: 2.1311 - val_accuracy: 0.1508\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 2.1029 - accuracy: 0.2300 - val_loss: 1.9890 - val_accuracy: 0.1859\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.9391 - accuracy: 0.2800 - val_loss: 2.0687 - val_accuracy: 0.2060\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.8377 - accuracy: 0.3350 - val_loss: 1.9668 - val_accuracy: 0.2362\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.6903 - accuracy: 0.3800 - val_loss: 1.8708 - val_accuracy: 0.2814\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.6706 - accuracy: 0.3963 - val_loss: 1.8319 - val_accuracy: 0.2764\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.5677 - accuracy: 0.4375 - val_loss: 2.2339 - val_accuracy: 0.3065\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.5458 - accuracy: 0.4487 - val_loss: 1.7502 - val_accuracy: 0.3266\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.4545 - accuracy: 0.4638 - val_loss: 1.8408 - val_accuracy: 0.3719\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 19s 1s/step - loss: 1.3557 - accuracy: 0.5000 - val_loss: 1.6961 - val_accuracy: 0.3920\n",
      "Found 800 images belonging to 10 classes.\n",
      "Found 199 images belonging to 10 classes.\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 2    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 3.3518 - accuracy: 0.1187 - val_loss: 2.1261 - val_accuracy: 0.2010\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 13s 1s/step - loss: 2.0624 - accuracy: 0.2575 - val_loss: 1.9918 - val_accuracy: 0.2613\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 13s 963ms/step - loss: 1.7225 - accuracy: 0.4013 - val_loss: 2.1085 - val_accuracy: 0.3065\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 13s 966ms/step - loss: 1.3892 - accuracy: 0.5325 - val_loss: 1.8866 - val_accuracy: 0.3166\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 13s 966ms/step - loss: 1.1515 - accuracy: 0.6288 - val_loss: 1.9096 - val_accuracy: 0.3819\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 13s 962ms/step - loss: 0.9427 - accuracy: 0.6725 - val_loss: 1.9629 - val_accuracy: 0.3467\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 13s 965ms/step - loss: 0.7256 - accuracy: 0.7663 - val_loss: 1.8136 - val_accuracy: 0.4322\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 13s 970ms/step - loss: 0.5840 - accuracy: 0.8138 - val_loss: 1.7935 - val_accuracy: 0.4724\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 13s 966ms/step - loss: 0.3789 - accuracy: 0.9025 - val_loss: 2.1993 - val_accuracy: 0.3467\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 13s 978ms/step - loss: 0.3112 - accuracy: 0.9275 - val_loss: 2.1129 - val_accuracy: 0.4322\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 3    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 13s 946ms/step - loss: 2.4621 - accuracy: 0.1675 - val_loss: 2.0032 - val_accuracy: 0.3015\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 12s 896ms/step - loss: 1.8938 - accuracy: 0.3013 - val_loss: 1.8776 - val_accuracy: 0.2663\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 12s 907ms/step - loss: 1.6861 - accuracy: 0.4062 - val_loss: 1.9370 - val_accuracy: 0.2613\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 12s 899ms/step - loss: 1.5859 - accuracy: 0.4387 - val_loss: 1.8643 - val_accuracy: 0.3467\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 12s 891ms/step - loss: 1.5276 - accuracy: 0.4613 - val_loss: 1.8125 - val_accuracy: 0.3668\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 12s 895ms/step - loss: 1.4563 - accuracy: 0.4475 - val_loss: 1.8010 - val_accuracy: 0.3116\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 12s 886ms/step - loss: 1.3642 - accuracy: 0.5038 - val_loss: 1.5724 - val_accuracy: 0.3668\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 12s 895ms/step - loss: 1.1674 - accuracy: 0.5813 - val_loss: 1.5834 - val_accuracy: 0.4121\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 12s 895ms/step - loss: 1.0765 - accuracy: 0.6175 - val_loss: 1.5119 - val_accuracy: 0.4271\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 12s 891ms/step - loss: 0.9142 - accuracy: 0.6700 - val_loss: 1.5369 - val_accuracy: 0.4422\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 4    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 13s 910ms/step - loss: 2.2426 - accuracy: 0.1713 - val_loss: 1.9815 - val_accuracy: 0.3216\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 12s 885ms/step - loss: 1.8995 - accuracy: 0.3038 - val_loss: 1.9941 - val_accuracy: 0.2965\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 12s 883ms/step - loss: 1.8098 - accuracy: 0.3175 - val_loss: 1.9691 - val_accuracy: 0.2714\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 12s 881ms/step - loss: 1.6707 - accuracy: 0.3963 - val_loss: 1.8225 - val_accuracy: 0.3467\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 12s 884ms/step - loss: 1.5724 - accuracy: 0.4112 - val_loss: 1.7563 - val_accuracy: 0.3568\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 11s 871ms/step - loss: 1.5202 - accuracy: 0.4300 - val_loss: 1.8558 - val_accuracy: 0.2613\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 12s 887ms/step - loss: 1.4212 - accuracy: 0.4825 - val_loss: 1.7961 - val_accuracy: 0.3719\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 11s 873ms/step - loss: 1.2856 - accuracy: 0.5375 - val_loss: 1.8166 - val_accuracy: 0.3819\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 12s 877ms/step - loss: 1.2348 - accuracy: 0.5462 - val_loss: 1.8290 - val_accuracy: 0.3166\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 12s 885ms/step - loss: 1.3459 - accuracy: 0.5125 - val_loss: 1.6432 - val_accuracy: 0.3668\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 2    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 15s 1s/step - loss: 3.2425 - accuracy: 0.1100 - val_loss: 2.1469 - val_accuracy: 0.2161\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 2.0397 - accuracy: 0.2637 - val_loss: 2.1465 - val_accuracy: 0.3116\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.7249 - accuracy: 0.3963 - val_loss: 2.0650 - val_accuracy: 0.3568\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 15s 1s/step - loss: 1.4140 - accuracy: 0.4988 - val_loss: 1.9251 - val_accuracy: 0.3166\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.2946 - accuracy: 0.5500 - val_loss: 1.8969 - val_accuracy: 0.3166\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.0641 - accuracy: 0.6463 - val_loss: 2.2051 - val_accuracy: 0.3920\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.9360 - accuracy: 0.6888 - val_loss: 1.9255 - val_accuracy: 0.3970\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.7904 - accuracy: 0.7300 - val_loss: 2.1365 - val_accuracy: 0.3367\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.7117 - accuracy: 0.7738 - val_loss: 2.4659 - val_accuracy: 0.3869\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.5399 - accuracy: 0.8313 - val_loss: 2.4758 - val_accuracy: 0.3769\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 3    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 15s 1s/step - loss: 2.2805 - accuracy: 0.1525 - val_loss: 2.1907 - val_accuracy: 0.2714\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.9183 - accuracy: 0.3025 - val_loss: 1.8656 - val_accuracy: 0.3065\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.7361 - accuracy: 0.3650 - val_loss: 2.1073 - val_accuracy: 0.2965\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.6619 - accuracy: 0.4038 - val_loss: 1.8838 - val_accuracy: 0.2864\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.4401 - accuracy: 0.4663 - val_loss: 1.7135 - val_accuracy: 0.4070\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.3511 - accuracy: 0.5200 - val_loss: 1.6968 - val_accuracy: 0.4322\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.2102 - accuracy: 0.5638 - val_loss: 1.8472 - val_accuracy: 0.3668\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.1188 - accuracy: 0.5950 - val_loss: 1.6049 - val_accuracy: 0.4271\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.9911 - accuracy: 0.6488 - val_loss: 1.6688 - val_accuracy: 0.4422\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.9867 - accuracy: 0.6463 - val_loss: 1.9575 - val_accuracy: 0.4523\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 4    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 15s 1s/step - loss: 2.2811 - accuracy: 0.1637 - val_loss: 2.0346 - val_accuracy: 0.2915\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 2.0480 - accuracy: 0.2675 - val_loss: 2.0256 - val_accuracy: 0.2060\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.9245 - accuracy: 0.2988 - val_loss: 2.0341 - val_accuracy: 0.2864\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.8295 - accuracy: 0.2750 - val_loss: 1.9561 - val_accuracy: 0.2513\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.7020 - accuracy: 0.3550 - val_loss: 2.0229 - val_accuracy: 0.2261\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.6621 - accuracy: 0.3900 - val_loss: 1.9287 - val_accuracy: 0.2613\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.6249 - accuracy: 0.3875 - val_loss: 1.7998 - val_accuracy: 0.2814\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.5103 - accuracy: 0.4538 - val_loss: 1.7781 - val_accuracy: 0.3116\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.4223 - accuracy: 0.4825 - val_loss: 1.8159 - val_accuracy: 0.3367\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 14s 1s/step - loss: 1.4036 - accuracy: 0.4875 - val_loss: 1.7124 - val_accuracy: 0.3869\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 2    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 27s 2s/step - loss: 4.5902 - accuracy: 0.1175 - val_loss: 2.1756 - val_accuracy: 0.1759\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 2.0201 - accuracy: 0.2775 - val_loss: 1.8239 - val_accuracy: 0.3719\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 1.6516 - accuracy: 0.4175 - val_loss: 2.0224 - val_accuracy: 0.3216\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 1.3393 - accuracy: 0.5200 - val_loss: 1.8332 - val_accuracy: 0.3317\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 1.0778 - accuracy: 0.6350 - val_loss: 1.9585 - val_accuracy: 0.3869\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 0.8818 - accuracy: 0.7038 - val_loss: 1.5560 - val_accuracy: 0.3920\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 0.6494 - accuracy: 0.8050 - val_loss: 1.6203 - val_accuracy: 0.4523\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 0.4460 - accuracy: 0.8725 - val_loss: 1.7633 - val_accuracy: 0.4422\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 0.3627 - accuracy: 0.8938 - val_loss: 1.7617 - val_accuracy: 0.4724\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 26s 2s/step - loss: 0.3700 - accuracy: 0.9025 - val_loss: 1.5461 - val_accuracy: 0.5226\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 3    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 25s 2s/step - loss: 2.2688 - accuracy: 0.2175 - val_loss: 2.0413 - val_accuracy: 0.2864\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.8919 - accuracy: 0.3113 - val_loss: 1.8434 - val_accuracy: 0.2362\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.6695 - accuracy: 0.3837 - val_loss: 1.7889 - val_accuracy: 0.3216\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.4391 - accuracy: 0.4938 - val_loss: 1.6661 - val_accuracy: 0.3467\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.2497 - accuracy: 0.5425 - val_loss: 1.5609 - val_accuracy: 0.3769\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.1785 - accuracy: 0.5738 - val_loss: 1.7408 - val_accuracy: 0.3568\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.0414 - accuracy: 0.6288 - val_loss: 1.4609 - val_accuracy: 0.5025\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 0.8741 - accuracy: 0.7063 - val_loss: 1.6449 - val_accuracy: 0.4774\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 0.8493 - accuracy: 0.7025 - val_loss: 1.7032 - val_accuracy: 0.4372\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 0.7435 - accuracy: 0.7450 - val_loss: 1.9134 - val_accuracy: 0.4673\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 4    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 25s 2s/step - loss: 2.3151 - accuracy: 0.1063 - val_loss: 2.1960 - val_accuracy: 0.1658\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 2.1455 - accuracy: 0.1937 - val_loss: 2.0905 - val_accuracy: 0.2563\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 2.0346 - accuracy: 0.2562 - val_loss: 2.0757 - val_accuracy: 0.2161\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.9213 - accuracy: 0.2738 - val_loss: 2.0671 - val_accuracy: 0.2764\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.7935 - accuracy: 0.3275 - val_loss: 2.0534 - val_accuracy: 0.2814\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.6870 - accuracy: 0.4050 - val_loss: 1.9366 - val_accuracy: 0.3216\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.6448 - accuracy: 0.3963 - val_loss: 1.8197 - val_accuracy: 0.2915\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.5015 - accuracy: 0.4588 - val_loss: 1.7687 - val_accuracy: 0.3518\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.4237 - accuracy: 0.4938 - val_loss: 1.6731 - val_accuracy: 0.4070\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 24s 2s/step - loss: 1.3638 - accuracy: 0.4975 - val_loss: 1.8825 - val_accuracy: 0.3819\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 2    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 4.0723 - accuracy: 0.1400 - val_loss: 2.1471 - val_accuracy: 0.2211\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 38s 3s/step - loss: 1.9784 - accuracy: 0.2400 - val_loss: 2.0358 - val_accuracy: 0.1910\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 37s 3s/step - loss: 1.7972 - accuracy: 0.3450 - val_loss: 1.9669 - val_accuracy: 0.2261\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 38s 3s/step - loss: 1.6275 - accuracy: 0.4412 - val_loss: 1.8556 - val_accuracy: 0.3166\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 38s 3s/step - loss: 1.3835 - accuracy: 0.4963 - val_loss: 1.9449 - val_accuracy: 0.2864\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 38s 3s/step - loss: 1.1916 - accuracy: 0.5700 - val_loss: 1.8162 - val_accuracy: 0.3719\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 38s 3s/step - loss: 0.9916 - accuracy: 0.6625 - val_loss: 1.7163 - val_accuracy: 0.4171\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 37s 3s/step - loss: 0.8809 - accuracy: 0.6950 - val_loss: 1.7489 - val_accuracy: 0.4070\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 38s 3s/step - loss: 0.6701 - accuracy: 0.7663 - val_loss: 2.0165 - val_accuracy: 0.4472\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 38s 3s/step - loss: 0.4820 - accuracy: 0.8350 - val_loss: 1.9642 - val_accuracy: 0.4724\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 3    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 40s 3s/step - loss: 2.5218 - accuracy: 0.1037 - val_loss: 2.2460 - val_accuracy: 0.1307\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 2.0254 - accuracy: 0.2825 - val_loss: 2.0193 - val_accuracy: 0.2864\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.8044 - accuracy: 0.3475 - val_loss: 1.9813 - val_accuracy: 0.2412\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.7385 - accuracy: 0.3537 - val_loss: 1.8547 - val_accuracy: 0.2714\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.5903 - accuracy: 0.4225 - val_loss: 1.8882 - val_accuracy: 0.2563\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.5278 - accuracy: 0.4300 - val_loss: 1.7900 - val_accuracy: 0.3266\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.4289 - accuracy: 0.4663 - val_loss: 1.7241 - val_accuracy: 0.4070\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.3351 - accuracy: 0.5113 - val_loss: 1.6893 - val_accuracy: 0.3920\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.3238 - accuracy: 0.5387 - val_loss: 1.7236 - val_accuracy: 0.3618\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.3219 - accuracy: 0.5163 - val_loss: 1.7586 - val_accuracy: 0.4372\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (256, 256)    Number of convolution layers: 4    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 40s 3s/step - loss: 2.3194 - accuracy: 0.1075 - val_loss: 2.1914 - val_accuracy: 0.2161\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 38s 3s/step - loss: 2.0793 - accuracy: 0.2300 - val_loss: 1.9880 - val_accuracy: 0.2412\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.9924 - accuracy: 0.2837 - val_loss: 2.0125 - val_accuracy: 0.1859\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.7896 - accuracy: 0.3275 - val_loss: 2.0268 - val_accuracy: 0.2462\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.6809 - accuracy: 0.3800 - val_loss: 1.9541 - val_accuracy: 0.3367\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.6258 - accuracy: 0.3900 - val_loss: 1.8921 - val_accuracy: 0.3266\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.6002 - accuracy: 0.3887 - val_loss: 2.0991 - val_accuracy: 0.2965\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.5989 - accuracy: 0.4200 - val_loss: 1.8516 - val_accuracy: 0.3015\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.4888 - accuracy: 0.4263 - val_loss: 1.7866 - val_accuracy: 0.3015\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 39s 3s/step - loss: 1.4154 - accuracy: 0.5000 - val_loss: 1.6128 - val_accuracy: 0.3920\n",
      "Found 800 images belonging to 10 classes.\n",
      "Found 199 images belonging to 10 classes.\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 2    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 8s 595ms/step - loss: 2.3087 - accuracy: 0.1813 - val_loss: 1.9793 - val_accuracy: 0.3417\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 7s 547ms/step - loss: 1.8946 - accuracy: 0.3325 - val_loss: 1.7908 - val_accuracy: 0.3266\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 7s 546ms/step - loss: 1.7288 - accuracy: 0.3837 - val_loss: 1.8516 - val_accuracy: 0.2864\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 1.5304 - accuracy: 0.4563 - val_loss: 1.6747 - val_accuracy: 0.3367\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 7s 546ms/step - loss: 1.3518 - accuracy: 0.5350 - val_loss: 1.7762 - val_accuracy: 0.3769\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 7s 536ms/step - loss: 1.1953 - accuracy: 0.5850 - val_loss: 1.8472 - val_accuracy: 0.3618\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 7s 547ms/step - loss: 1.0159 - accuracy: 0.6388 - val_loss: 1.9738 - val_accuracy: 0.3668\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 7s 570ms/step - loss: 0.8513 - accuracy: 0.7212 - val_loss: 1.6833 - val_accuracy: 0.3869\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 7s 551ms/step - loss: 0.7055 - accuracy: 0.7788 - val_loss: 1.7501 - val_accuracy: 0.3970\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 0.6073 - accuracy: 0.7987 - val_loss: 1.8183 - val_accuracy: 0.4472\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 3    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 9s 624ms/step - loss: 2.2514 - accuracy: 0.1963 - val_loss: 2.0582 - val_accuracy: 0.2714\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 7s 575ms/step - loss: 1.9412 - accuracy: 0.3063 - val_loss: 1.9259 - val_accuracy: 0.3568\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 7s 538ms/step - loss: 1.8045 - accuracy: 0.3475 - val_loss: 1.9531 - val_accuracy: 0.2513\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 7s 527ms/step - loss: 1.6763 - accuracy: 0.4038 - val_loss: 1.8489 - val_accuracy: 0.3015\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 7s 527ms/step - loss: 1.5755 - accuracy: 0.4150 - val_loss: 1.7567 - val_accuracy: 0.3417\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 7s 526ms/step - loss: 1.4664 - accuracy: 0.4700 - val_loss: 1.6637 - val_accuracy: 0.3467\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 1.3436 - accuracy: 0.5213 - val_loss: 1.8241 - val_accuracy: 0.3216\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 7s 529ms/step - loss: 1.2441 - accuracy: 0.5525 - val_loss: 1.8522 - val_accuracy: 0.4422\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 1.2263 - accuracy: 0.5562 - val_loss: 1.9156 - val_accuracy: 0.3920\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 7s 527ms/step - loss: 1.1656 - accuracy: 0.5700 - val_loss: 1.8925 - val_accuracy: 0.4171\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 4    Number of filters: 32   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 8s 563ms/step - loss: 2.2705 - accuracy: 0.1625 - val_loss: 2.1102 - val_accuracy: 0.2211\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 2.0116 - accuracy: 0.2375 - val_loss: 1.9007 - val_accuracy: 0.3417\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 7s 536ms/step - loss: 1.8374 - accuracy: 0.3325 - val_loss: 1.8219 - val_accuracy: 0.3116\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 7s 526ms/step - loss: 1.7680 - accuracy: 0.3663 - val_loss: 1.7012 - val_accuracy: 0.3568\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 7s 533ms/step - loss: 1.6996 - accuracy: 0.3688 - val_loss: 1.6459 - val_accuracy: 0.3769\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 7s 518ms/step - loss: 1.5678 - accuracy: 0.4288 - val_loss: 1.7675 - val_accuracy: 0.3719\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 1.5603 - accuracy: 0.4300 - val_loss: 1.7204 - val_accuracy: 0.3518\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 7s 516ms/step - loss: 1.4533 - accuracy: 0.4900 - val_loss: 1.7131 - val_accuracy: 0.3467\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 7s 513ms/step - loss: 1.3678 - accuracy: 0.4963 - val_loss: 1.9402 - val_accuracy: 0.3568\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 1.3922 - accuracy: 0.4863 - val_loss: 1.6373 - val_accuracy: 0.4020\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 2    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 8s 601ms/step - loss: 2.4023 - accuracy: 0.1637 - val_loss: 2.0223 - val_accuracy: 0.2412\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 7s 583ms/step - loss: 1.8837 - accuracy: 0.2988 - val_loss: 1.8508 - val_accuracy: 0.3568\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 7s 563ms/step - loss: 1.6727 - accuracy: 0.3787 - val_loss: 1.8992 - val_accuracy: 0.2613\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 7s 570ms/step - loss: 1.5916 - accuracy: 0.4313 - val_loss: 1.8653 - val_accuracy: 0.2764\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 7s 558ms/step - loss: 1.4657 - accuracy: 0.4737 - val_loss: 1.9925 - val_accuracy: 0.4121\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 7s 587ms/step - loss: 1.4359 - accuracy: 0.4750 - val_loss: 1.6767 - val_accuracy: 0.3970\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 7s 572ms/step - loss: 1.2001 - accuracy: 0.5875 - val_loss: 1.8147 - val_accuracy: 0.3618\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 7s 564ms/step - loss: 1.1392 - accuracy: 0.6050 - val_loss: 1.9278 - val_accuracy: 0.3568\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 7s 565ms/step - loss: 0.9818 - accuracy: 0.6675 - val_loss: 1.8035 - val_accuracy: 0.3920\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 7s 565ms/step - loss: 0.8706 - accuracy: 0.7063 - val_loss: 1.6770 - val_accuracy: 0.4673\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 3    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 8s 591ms/step - loss: 2.2403 - accuracy: 0.1562 - val_loss: 2.0599 - val_accuracy: 0.1357\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 7s 550ms/step - loss: 1.9907 - accuracy: 0.2738 - val_loss: 1.9819 - val_accuracy: 0.3216\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 1.8308 - accuracy: 0.3425 - val_loss: 1.8545 - val_accuracy: 0.2563\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 7s 547ms/step - loss: 1.7346 - accuracy: 0.3550 - val_loss: 1.8095 - val_accuracy: 0.3266\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 7s 548ms/step - loss: 1.6677 - accuracy: 0.3963 - val_loss: 1.8100 - val_accuracy: 0.2312\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 7s 552ms/step - loss: 1.5770 - accuracy: 0.4300 - val_loss: 1.8251 - val_accuracy: 0.3367\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 7s 549ms/step - loss: 1.5133 - accuracy: 0.4375 - val_loss: 1.6490 - val_accuracy: 0.3869\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 7s 557ms/step - loss: 1.4331 - accuracy: 0.4837 - val_loss: 1.6762 - val_accuracy: 0.3618\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 7s 549ms/step - loss: 1.4368 - accuracy: 0.4625 - val_loss: 1.7002 - val_accuracy: 0.3417\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 7s 548ms/step - loss: 1.3559 - accuracy: 0.5250 - val_loss: 2.0351 - val_accuracy: 0.3116\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 4    Number of filters: 32   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 9s 636ms/step - loss: 2.2957 - accuracy: 0.1050 - val_loss: 2.2018 - val_accuracy: 0.1407\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 7s 555ms/step - loss: 2.1597 - accuracy: 0.1975 - val_loss: 2.0175 - val_accuracy: 0.2864\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 1.9418 - accuracy: 0.3125 - val_loss: 1.9029 - val_accuracy: 0.3417\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 7s 543ms/step - loss: 1.8419 - accuracy: 0.3325 - val_loss: 1.7917 - val_accuracy: 0.3266\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 1.7794 - accuracy: 0.3500 - val_loss: 1.9390 - val_accuracy: 0.3266\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 1.7260 - accuracy: 0.3975 - val_loss: 1.7032 - val_accuracy: 0.3819\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 1.6459 - accuracy: 0.4025 - val_loss: 1.9452 - val_accuracy: 0.3317\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 7s 552ms/step - loss: 1.6116 - accuracy: 0.4112 - val_loss: 1.8310 - val_accuracy: 0.3065\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 1.5390 - accuracy: 0.4450 - val_loss: 1.6473 - val_accuracy: 0.3920\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 1.4610 - accuracy: 0.4737 - val_loss: 1.7384 - val_accuracy: 0.3819\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 2    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 10s 740ms/step - loss: 2.5145 - accuracy: 0.1663 - val_loss: 2.1217 - val_accuracy: 0.2513\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 9s 709ms/step - loss: 1.9942 - accuracy: 0.2438 - val_loss: 1.9812 - val_accuracy: 0.2663\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 9s 713ms/step - loss: 1.7220 - accuracy: 0.3600 - val_loss: 1.9926 - val_accuracy: 0.3467\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 9s 702ms/step - loss: 1.5901 - accuracy: 0.4387 - val_loss: 1.8447 - val_accuracy: 0.3317\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 9s 710ms/step - loss: 1.3911 - accuracy: 0.5013 - val_loss: 1.7921 - val_accuracy: 0.3367\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 9s 715ms/step - loss: 1.1628 - accuracy: 0.6050 - val_loss: 1.7214 - val_accuracy: 0.4171\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 9s 721ms/step - loss: 1.0176 - accuracy: 0.6413 - val_loss: 1.6752 - val_accuracy: 0.4372\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 9s 709ms/step - loss: 0.8721 - accuracy: 0.7013 - val_loss: 1.9192 - val_accuracy: 0.4020\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 9s 711ms/step - loss: 0.7334 - accuracy: 0.7588 - val_loss: 1.6823 - val_accuracy: 0.4472\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 9s 709ms/step - loss: 0.5848 - accuracy: 0.8138 - val_loss: 1.9199 - val_accuracy: 0.4372\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 3    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 10s 728ms/step - loss: 2.1742 - accuracy: 0.2025 - val_loss: 1.9323 - val_accuracy: 0.2864\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 9s 717ms/step - loss: 1.7859 - accuracy: 0.3550 - val_loss: 1.7843 - val_accuracy: 0.3216\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 9s 688ms/step - loss: 1.6377 - accuracy: 0.3887 - val_loss: 1.8536 - val_accuracy: 0.3869\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 9s 699ms/step - loss: 1.4795 - accuracy: 0.4538 - val_loss: 1.7905 - val_accuracy: 0.3668\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 9s 687ms/step - loss: 1.4176 - accuracy: 0.4837 - val_loss: 1.9147 - val_accuracy: 0.3568\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 9s 681ms/step - loss: 1.3014 - accuracy: 0.5300 - val_loss: 1.7272 - val_accuracy: 0.3970\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 9s 694ms/step - loss: 1.2232 - accuracy: 0.5537 - val_loss: 1.6339 - val_accuracy: 0.4874\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 9s 684ms/step - loss: 1.1564 - accuracy: 0.5738 - val_loss: 1.8110 - val_accuracy: 0.4020\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 9s 684ms/step - loss: 1.0637 - accuracy: 0.6225 - val_loss: 1.7772 - val_accuracy: 0.4422\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 9s 690ms/step - loss: 1.0350 - accuracy: 0.6237 - val_loss: 1.8888 - val_accuracy: 0.4171\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 4    Number of filters: 64   Kernel size: (3, 3)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 10s 719ms/step - loss: 2.2773 - accuracy: 0.1388 - val_loss: 2.1488 - val_accuracy: 0.2211\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 9s 708ms/step - loss: 1.9366 - accuracy: 0.2988 - val_loss: 1.8156 - val_accuracy: 0.3216\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 9s 711ms/step - loss: 1.7967 - accuracy: 0.3487 - val_loss: 1.8405 - val_accuracy: 0.3166\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 9s 680ms/step - loss: 1.7328 - accuracy: 0.3487 - val_loss: 1.8472 - val_accuracy: 0.1910\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 9s 686ms/step - loss: 1.6456 - accuracy: 0.3850 - val_loss: 1.7928 - val_accuracy: 0.3317\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 9s 684ms/step - loss: 1.5737 - accuracy: 0.4288 - val_loss: 1.7712 - val_accuracy: 0.3216\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 9s 719ms/step - loss: 1.5468 - accuracy: 0.4263 - val_loss: 1.8829 - val_accuracy: 0.3065\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 9s 680ms/step - loss: 1.4791 - accuracy: 0.4600 - val_loss: 1.7070 - val_accuracy: 0.3417\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 9s 687ms/step - loss: 1.4001 - accuracy: 0.4837 - val_loss: 2.0250 - val_accuracy: 0.3216\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 9s 679ms/step - loss: 1.4712 - accuracy: 0.4575 - val_loss: 1.6682 - val_accuracy: 0.3668\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 2    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 12s 866ms/step - loss: 2.5762 - accuracy: 0.1612 - val_loss: 2.0623 - val_accuracy: 0.2362\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 11s 830ms/step - loss: 1.8629 - accuracy: 0.2988 - val_loss: 2.0859 - val_accuracy: 0.2613\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 11s 838ms/step - loss: 1.7859 - accuracy: 0.3613 - val_loss: 1.8666 - val_accuracy: 0.3116\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 11s 819ms/step - loss: 1.5679 - accuracy: 0.4338 - val_loss: 1.8224 - val_accuracy: 0.3719\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 11s 826ms/step - loss: 1.4915 - accuracy: 0.4750 - val_loss: 1.9387 - val_accuracy: 0.3166\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 11s 826ms/step - loss: 1.2484 - accuracy: 0.5387 - val_loss: 1.5389 - val_accuracy: 0.4221\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 11s 828ms/step - loss: 1.1922 - accuracy: 0.5550 - val_loss: 1.7420 - val_accuracy: 0.4221\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 11s 819ms/step - loss: 1.0806 - accuracy: 0.6025 - val_loss: 1.9443 - val_accuracy: 0.4573\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 11s 831ms/step - loss: 0.9122 - accuracy: 0.6775 - val_loss: 1.5870 - val_accuracy: 0.4824\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 11s 831ms/step - loss: 0.8978 - accuracy: 0.6762 - val_loss: 2.0071 - val_accuracy: 0.4472\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 3    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 12s 860ms/step - loss: 2.2672 - accuracy: 0.1750 - val_loss: 2.0777 - val_accuracy: 0.2261\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 11s 837ms/step - loss: 1.9650 - accuracy: 0.2812 - val_loss: 1.9265 - val_accuracy: 0.3116\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 11s 826ms/step - loss: 1.8154 - accuracy: 0.3400 - val_loss: 1.8091 - val_accuracy: 0.3116\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 11s 829ms/step - loss: 1.6772 - accuracy: 0.3825 - val_loss: 1.8930 - val_accuracy: 0.3116\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 11s 821ms/step - loss: 1.5554 - accuracy: 0.4150 - val_loss: 1.8216 - val_accuracy: 0.2915\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 11s 820ms/step - loss: 1.5674 - accuracy: 0.4387 - val_loss: 2.0142 - val_accuracy: 0.2965\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 11s 814ms/step - loss: 1.4975 - accuracy: 0.4563 - val_loss: 1.7062 - val_accuracy: 0.3015\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 11s 826ms/step - loss: 1.3226 - accuracy: 0.5238 - val_loss: 1.7258 - val_accuracy: 0.4221\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 11s 827ms/step - loss: 1.2696 - accuracy: 0.5275 - val_loss: 1.8138 - val_accuracy: 0.3819\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 11s 858ms/step - loss: 1.2515 - accuracy: 0.5437 - val_loss: 1.6926 - val_accuracy: 0.3920\n",
      "\n",
      "Training with the hyperparameters:\n",
      "Image size: (128, 128)    Number of convolution layers: 4    Number of filters: 64   Kernel size: (5, 5)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 12s 860ms/step - loss: 2.2592 - accuracy: 0.1425 - val_loss: 2.0387 - val_accuracy: 0.2161\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 11s 812ms/step - loss: 2.0566 - accuracy: 0.2288 - val_loss: 1.9917 - val_accuracy: 0.2513\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 11s 814ms/step - loss: 1.9303 - accuracy: 0.2600 - val_loss: 1.8476 - val_accuracy: 0.3568\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 11s 812ms/step - loss: 1.8209 - accuracy: 0.3237 - val_loss: 1.7949 - val_accuracy: 0.2915\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 11s 816ms/step - loss: 1.7096 - accuracy: 0.3575 - val_loss: 1.6288 - val_accuracy: 0.3618\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 11s 813ms/step - loss: 1.6970 - accuracy: 0.3787 - val_loss: 1.6648 - val_accuracy: 0.4070\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 11s 824ms/step - loss: 1.6004 - accuracy: 0.4263 - val_loss: 1.6469 - val_accuracy: 0.3668\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 11s 820ms/step - loss: 1.5057 - accuracy: 0.4412 - val_loss: 1.9017 - val_accuracy: 0.3317\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 11s 809ms/step - loss: 1.5157 - accuracy: 0.4338 - val_loss: 1.6644 - val_accuracy: 0.3417\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 11s 819ms/step - loss: 1.4067 - accuracy: 0.4875 - val_loss: 1.5792 - val_accuracy: 0.4171\n"
     ]
    }
   ],
   "source": [
    "# Call the comparison function with the lists and the path. Takes around 1.5 hr \n",
    "results = model_comparison(data_folder, img_size_list=img_size_list, num_filters_list=num_filters_list, kernel_size_list=kernel_size_list, num_conv_layers_list=num_conv_layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_size</th>\n",
       "      <th>num_conv_layers</th>\n",
       "      <th>num_filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>train loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.493</td>\n",
       "      <td>1.715</td>\n",
       "      <td>94.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1.564</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.382</td>\n",
       "      <td>1.310</td>\n",
       "      <td>1.726</td>\n",
       "      <td>88.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.804</td>\n",
       "      <td>1.812</td>\n",
       "      <td>103.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.407</td>\n",
       "      <td>1.146</td>\n",
       "      <td>1.785</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.322</td>\n",
       "      <td>1.421</td>\n",
       "      <td>1.742</td>\n",
       "      <td>102.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.422</td>\n",
       "      <td>2.356</td>\n",
       "      <td>141.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.432</td>\n",
       "      <td>1.073</td>\n",
       "      <td>1.997</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.442</td>\n",
       "      <td>1.307</td>\n",
       "      <td>1.689</td>\n",
       "      <td>130.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.352</td>\n",
       "      <td>1.293</td>\n",
       "      <td>1.915</td>\n",
       "      <td>190.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.412</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.960</td>\n",
       "      <td>192.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.356</td>\n",
       "      <td>1.696</td>\n",
       "      <td>190.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.311</td>\n",
       "      <td>2.113</td>\n",
       "      <td>128.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.914</td>\n",
       "      <td>1.537</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.367</td>\n",
       "      <td>1.346</td>\n",
       "      <td>1.643</td>\n",
       "      <td>117.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.540</td>\n",
       "      <td>2.476</td>\n",
       "      <td>145.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.957</td>\n",
       "      <td>140.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.387</td>\n",
       "      <td>1.404</td>\n",
       "      <td>1.712</td>\n",
       "      <td>138.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.370</td>\n",
       "      <td>1.546</td>\n",
       "      <td>259.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.743</td>\n",
       "      <td>1.913</td>\n",
       "      <td>244.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.382</td>\n",
       "      <td>1.364</td>\n",
       "      <td>1.882</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.482</td>\n",
       "      <td>1.964</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.437</td>\n",
       "      <td>1.322</td>\n",
       "      <td>1.759</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.415</td>\n",
       "      <td>1.613</td>\n",
       "      <td>387.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.607</td>\n",
       "      <td>1.818</td>\n",
       "      <td>73.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.417</td>\n",
       "      <td>1.166</td>\n",
       "      <td>1.892</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.402</td>\n",
       "      <td>1.392</td>\n",
       "      <td>1.637</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.871</td>\n",
       "      <td>1.677</td>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.312</td>\n",
       "      <td>1.356</td>\n",
       "      <td>2.035</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.382</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.738</td>\n",
       "      <td>73.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.920</td>\n",
       "      <td>94.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.417</td>\n",
       "      <td>1.035</td>\n",
       "      <td>1.889</td>\n",
       "      <td>91.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.367</td>\n",
       "      <td>1.471</td>\n",
       "      <td>1.668</td>\n",
       "      <td>90.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.898</td>\n",
       "      <td>2.007</td>\n",
       "      <td>110.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.251</td>\n",
       "      <td>1.693</td>\n",
       "      <td>110.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(128, 128)</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.417</td>\n",
       "      <td>1.407</td>\n",
       "      <td>1.579</td>\n",
       "      <td>109.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_size  num_conv_layers  num_filters kernel_size  train accuracy  \\\n",
       "0   (256, 128)                2           32      (3, 3)           0.844   \n",
       "1   (256, 128)                3           32      (3, 3)           0.642   \n",
       "2   (256, 128)                4           32      (3, 3)           0.519   \n",
       "3   (256, 128)                2           32      (5, 5)           0.734   \n",
       "4   (256, 128)                3           32      (5, 5)           0.585   \n",
       "5   (256, 128)                4           32      (5, 5)           0.494   \n",
       "6   (256, 128)                2           64      (3, 3)           0.868   \n",
       "7   (256, 128)                3           64      (3, 3)           0.611   \n",
       "8   (256, 128)                4           64      (3, 3)           0.525   \n",
       "9   (256, 128)                2           64      (5, 5)           0.540   \n",
       "10  (256, 128)                3           64      (5, 5)           0.613   \n",
       "11  (256, 128)                4           64      (5, 5)           0.500   \n",
       "12  (256, 256)                2           32      (3, 3)           0.928   \n",
       "13  (256, 256)                3           32      (3, 3)           0.670   \n",
       "14  (256, 256)                4           32      (3, 3)           0.512   \n",
       "15  (256, 256)                2           32      (5, 5)           0.831   \n",
       "16  (256, 256)                3           32      (5, 5)           0.646   \n",
       "17  (256, 256)                4           32      (5, 5)           0.488   \n",
       "18  (256, 256)                2           64      (3, 3)           0.902   \n",
       "19  (256, 256)                3           64      (3, 3)           0.745   \n",
       "20  (256, 256)                4           64      (3, 3)           0.498   \n",
       "21  (256, 256)                2           64      (5, 5)           0.835   \n",
       "22  (256, 256)                3           64      (5, 5)           0.516   \n",
       "23  (256, 256)                4           64      (5, 5)           0.500   \n",
       "24  (128, 128)                2           32      (3, 3)           0.799   \n",
       "25  (128, 128)                3           32      (3, 3)           0.570   \n",
       "26  (128, 128)                4           32      (3, 3)           0.486   \n",
       "27  (128, 128)                2           32      (5, 5)           0.706   \n",
       "28  (128, 128)                3           32      (5, 5)           0.525   \n",
       "29  (128, 128)                4           32      (5, 5)           0.474   \n",
       "30  (128, 128)                2           64      (3, 3)           0.814   \n",
       "31  (128, 128)                3           64      (3, 3)           0.624   \n",
       "32  (128, 128)                4           64      (3, 3)           0.458   \n",
       "33  (128, 128)                2           64      (5, 5)           0.676   \n",
       "34  (128, 128)                3           64      (5, 5)           0.544   \n",
       "35  (128, 128)                4           64      (5, 5)           0.488   \n",
       "\n",
       "    test accuracy  train loss  test_loss  training time  \n",
       "0           0.422       0.493      1.715           94.2  \n",
       "1           0.472       0.985      1.564           88.4  \n",
       "2           0.382       1.310      1.726           88.6  \n",
       "3           0.447       0.804      1.812          103.1  \n",
       "4           0.407       1.146      1.785           98.9  \n",
       "5           0.322       1.421      1.742          102.5  \n",
       "6           0.407       0.422      2.356          141.2  \n",
       "7           0.432       1.073      1.997          133.0  \n",
       "8           0.442       1.307      1.689          130.9  \n",
       "9           0.352       1.293      1.915          190.2  \n",
       "10          0.412       1.098      1.960          192.4  \n",
       "11          0.392       1.356      1.696          190.1  \n",
       "12          0.432       0.311      2.113          128.8  \n",
       "13          0.442       0.914      1.537          119.4  \n",
       "14          0.367       1.346      1.643          117.2  \n",
       "15          0.377       0.540      2.476          145.7  \n",
       "16          0.452       0.987      1.957          140.3  \n",
       "17          0.387       1.404      1.712          138.5  \n",
       "18          0.523       0.370      1.546          259.9  \n",
       "19          0.467       0.743      1.913          244.3  \n",
       "20          0.382       1.364      1.882          240.0  \n",
       "21          0.472       0.482      1.964          378.0  \n",
       "22          0.437       1.322      1.759          390.0  \n",
       "23          0.392       1.415      1.613          387.8  \n",
       "24          0.447       0.607      1.818           73.1  \n",
       "25          0.417       1.166      1.892           71.3  \n",
       "26          0.402       1.392      1.637           69.2  \n",
       "27          0.467       0.871      1.677           74.9  \n",
       "28          0.312       1.356      2.035           73.0  \n",
       "29          0.382       1.461      1.738           73.3  \n",
       "30          0.437       0.585      1.920           94.6  \n",
       "31          0.417       1.035      1.889           91.7  \n",
       "32          0.367       1.471      1.668           90.9  \n",
       "33          0.447       0.898      2.007          110.6  \n",
       "34          0.392       1.251      1.693          110.2  \n",
       "35          0.417       1.407      1.579          109.3  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results as an excel file. Saves in same folder as default. Change the variable where2Write if needed. \n",
    "where2Write = 'cnn_stft'\n",
    "results.to_excel(where2Write + '.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates impacts of each parameter on the test accuracy. Uses a correlation matrix to do so. \n",
    "def calculate_impacts(df):\n",
    "    df_copy = df.copy()    # Works on a copy not to be 'Pythoned'\n",
    "\n",
    "    # Function for mapping img size to integer values as they are not\n",
    "    def map_img_size(value):\n",
    "        if value == \"(256, 128)\":\n",
    "            return 1.5\n",
    "        elif value == \"(256, 256)\":\n",
    "            return 2\n",
    "        elif value == \"(128, 128)\":\n",
    "            return 1\n",
    "\n",
    "    # Apply map function on the corresponded column.    \n",
    "    df_copy['img_size'] = df_copy['img_size'].apply(lambda x: map_img_size(x))\n",
    "\n",
    "    # Same operations above for kernel_size\n",
    "    def map_kernel_size(value):\n",
    "        if value == \"(3, 3)\":\n",
    "            return 3\n",
    "        elif value == \"(5, 5)\":\n",
    "            return 5\n",
    "\n",
    "    df_copy['kernel_size'] = df_copy['kernel_size'].apply(lambda x: map_kernel_size(x))\n",
    "\n",
    "    # Columns that are going to be calculated for impact\n",
    "    columns_of_interest = ['img_size', 'num_conv_layers', 'num_filters', 'kernel_size', 'test accuracy']\n",
    "\n",
    "    # Create a new DataFrame with only the selected columns\n",
    "    df_selected = df_copy[columns_of_interest]\n",
    "\n",
    "    # Calculate correlation coefficients\n",
    "    correlation_matrix = df_selected.corr()\n",
    "\n",
    "    # Drop test accuracy from corr matrix to see others impact. Round 2 digit sensitivity. \n",
    "    impact_on_test_accuracy = correlation_matrix['test accuracy'].drop('test accuracy').round(2)\n",
    "\n",
    "    # Display the impact of each parameter on test accuracy\n",
    "    print(\"Impact on test accuracy:\")\n",
    "    print(impact_on_test_accuracy)\n",
    "    del df_copy     # Clears memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact on test accuracy:\n",
      "img_size           0.18\n",
      "num_conv_layers   -0.47\n",
      "num_filters        0.16\n",
      "kernel_size       -0.25\n",
      "Name: test accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "calculate_impacts(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
